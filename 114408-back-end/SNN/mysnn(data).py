# -*- coding: utf-8 -*-
"""Mysnn(data).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10bUSusjjSepcX6hrr6oy1MgD5FwAC7VU
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Lambda
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
import tensorflow as tf

# 加載資料集函數
def load_dataset(data_dir, img_size=(28, 28)):
    class_names = sorted(os.listdir(data_dir))  # 資料集中的類別名稱
    images = []
    labels = []

    # 讀取每一個類別的圖片
    for idx, class_name in enumerate(class_names):
        class_path = os.path.join(data_dir, class_name)
        if os.path.isdir(class_path):
            for img_name in os.listdir(class_path):
                img_path = os.path.join(class_path, img_name)
                img = load_img(img_path, target_size=img_size, color_mode='grayscale')
                img = img_to_array(img)
                images.append(img)
                labels.append(idx)

    images = np.array(images)
    labels = np.array(labels)

    return images, labels, class_names

# 設定資料集路徑
data_dir = "/content/drive/MyDrive/ticket"

# 加載資料集
images, labels, class_names = load_dataset(data_dir)

# 確保資料格式正確
images = images.astype('float32') / 255.0  # 轉換為浮點數並歸一化

# 如果需要展開成 (28, 28, 1) 的形狀
images = np.expand_dims(images, axis=-1)

# 拆分資料集為訓練集和測試集
train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)

import tensorflow as tf
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image

# 設定圖片資料夾路徑
image_directory = "/content/drive/MyDrive/ticket/class_2"  # 替換為你的圖片資料夾

# 建立 ImageDataGenerator 物件並設定擴增方法
datagen = ImageDataGenerator(
    rotation_range=40,        # 隨機旋轉圖片的角度
    width_shift_range=0.2,    # 隨機水平偏移
    height_shift_range=0.2,   # 隨機垂直偏移
    shear_range=0.2,          # 隨機錯切變換
    zoom_range=0.2,           # 隨機縮放
    horizontal_flip=True,     # 隨機水平翻轉
    fill_mode='nearest'       # 填補因擴增造成的空白區域
)

# 載入並顯示原始圖片
img = image.load_img(os.path.join(image_directory, '4.jpg'))  # 替換為你的圖片檔案
x = image.img_to_array(img)
x = x.reshape((1,) + x.shape)

# 設定顯示數量
fig, axes = plt.subplots(1, 5, figsize=(15, 15))
axes = axes.ravel()

# 開始產生擴增後的圖片
i = 0
for batch in datagen.flow(x, batch_size=1, save_to_dir="/content/drive/MyDrive/ticket/class_2", save_prefix='aug', save_format='jpg'):
    axes[i].imshow(image.array_to_img(batch[0]))
    axes[i].axis('off')
    i += 1
    if i > 4:  # 顯示5個擴增後的圖片
        break
plt.show()

# 定義了一個歐幾里得距離函數，用於計算兩個向量之間的距離
def euclidean_distance(vects):
    x, y = vects
    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_square, K.epsilon()))

# 基礎卷積神經網路，用於提取圖像特徵。包括兩個卷積層、池化層、展平層和全連接層
def create_base_network(input_shape):
    input = Input(shape=input_shape)
    x = Conv2D(32, (3, 3), activation='relu')(input)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu')(x)
    x = MaxPooling2D(pool_size=(2, 2))(x)
    x = Flatten()(x)
    x = Dense(128, activation='relu')(x)
    return Model(input, x)

# 定義對比損失函數，用於訓練孿生網路。根據標籤計算正負樣本對的損失
def contrastive_loss(y_true, y_pred):
    # 設定一個 margin 值，用來區分相似樣本對和不相似樣本對。這個值可以調整，但常見的設置是 1。
    margin = 1
    # 計算 y_pred 的平方。y_pred 是模型的輸出，即兩個嵌入向量之間的歐幾里得距離。平方是為了計算損失，使得遠距離差異更明顯。
    square_pred = K.square(y_pred)
    # 確保 margin 與距離之間的差不為負值（負值沒有意義），即如果 y_pred 大於 margin，則這部分損失為 0
    # 之後一樣用平方加大差距
    margin_square = K.square(K.maximum(margin - y_pred, 0))
    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)

import numpy as np

def create_pairs(x, digit_indices):
    pairs = []
    labels = []

    unique_classes = list(digit_indices.keys())  # 取得所有類別
    if len(unique_classes) < 2:
        raise ValueError("數據集中至少需要兩個不同的類別才能生成成對樣本。")

    # 確保所有類別至少有 2 個樣本
    min_samples = min([len(digit_indices[d]) for d in unique_classes])
    if min_samples < 2:
        raise ValueError(f"某些類別的樣本數少於 2，無法生成成對樣本。請檢查數據！\n{digit_indices}")

    n = min_samples - 1  # 確保 n 不會超過最小類別的數量

    for d in unique_classes:
        if len(digit_indices[d]) < 2:
            print(f"跳過類別 {d}，因為只有 {len(digit_indices[d])} 個樣本。")
            continue  # 如果某個類別樣本數小於 2，則跳過

        for i in range(n):
            if i + 1 >= len(digit_indices[d]):
                break  # 避免超出範圍

            # 相似樣本對
            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]
            pairs.append([x[z1], x[z2]])
            labels.append(1)

            # 選擇不同類別的樣本
            other_d = np.random.choice([cls for cls in unique_classes if cls != d])

            # 確保 other_d 中的索引有效
            random_idx = np.random.randint(len(digit_indices[other_d]))
            z1, z2 = digit_indices[d][i], digit_indices[other_d][random_idx]
            pairs.append([x[z1], x[z2]])
            labels.append(0)

    return np.array(pairs), np.array(labels).astype('float32')

input_shape = (28, 28, 1)
base_network = create_base_network(input_shape)

# 創建兩個輸入層，用於孿生網絡
input_a = Input(shape=input_shape)
input_b = Input(shape=input_shape)

# 基礎網絡處理兩個輸入，生成嵌入向量
processed_a = base_network(input_a)
processed_b = base_network(input_b)

# 計算兩個嵌入向量之間的歐幾里得距離
distance = Lambda(euclidean_distance, output_shape=(1,))([processed_a, processed_b])

# 使用對比損失和 Adam 優化器進行編譯
model = Model([input_a, input_b], distance)
model.compile(loss=contrastive_loss, optimizer=Adam(), metrics=['accuracy'])

# 創建基於 train_labels 的 digit_indices
unique_classes = np.unique(train_labels)
digit_indices = {cls: np.where(train_labels == cls)[0] for cls in unique_classes}

# **修正：使用 test_labels 建立 digit_indices**
unique_classes_test = np.unique(test_labels)
digit_indices_test = {cls: np.where(test_labels == cls)[0] for cls in unique_classes_test}

tr_pairs, tr_y = create_pairs(train_images, digit_indices)

# **修正：用 digit_indices_test 建立 te_pairs**
te_pairs, te_y = create_pairs(test_images, digit_indices_test)

# 訓練模型
model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,
          batch_size=128, epochs=10,
          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))

# 評估模型
results = model.evaluate([te_pairs[:, 0], te_pairs[:, 1]], te_y)
print("Test Loss, Test Accuracy:", results)

import numpy as np
import matplotlib.pyplot as plt

# 定義 helper 函數以顯示圖片和結果
def show_images_and_results(pairs, predictions):
    plt.figure(figsize=(10, 4))
    for i in range(len(pairs)):
        plt.subplot(2, 4, i * 2 + 1)
        plt.imshow(pairs[i][0].reshape(28, 28), cmap='gray')
        plt.title('Image 1')
        plt.axis('off')

        plt.subplot(2, 4, i * 2 + 2)
        plt.imshow(pairs[i][1].reshape(28, 28), cmap='gray')
        plt.title('Image 2\nDistance: {:.4f}'.format(predictions[i][0]))
        plt.axis('off')
    plt.tight_layout()
    plt.show()

# 選擇測試樣本
def get_sample_pairs(test_images, test_labels):
    pairs = []
    labels = []

    # 相同發票
    same_digit_indices_1 = np.where(test_labels == 0)[0]
    pairs.append([test_images[same_digit_indices_1[1]], test_images[same_digit_indices_1[2]]])
    labels.append(1)

    # 不同發票
    diff_digit_indices_1 = [np.where(test_labels == 0)[0][0], np.where(test_labels == 1)[0][1]]
    pairs.append([test_images[same_digit_indices_1[1]], test_images[diff_digit_indices_1[1]]])
    labels.append(0)

    # 發票跟收據
    diff_digit_indices_1 = [np.where(test_labels == 0)[0][0], np.where(test_labels == 2)[0][2]]
    pairs.append([test_images[same_digit_indices_1[1]], test_images[diff_digit_indices_1[1]]])
    labels.append(0)

    return np.array(pairs), np.array(labels).astype('float32')

# 取得樣本對
sample_pairs, sample_labels = get_sample_pairs(test_images, test_labels)

# 使用模型進行預測
predictions = model.predict([sample_pairs[:, 0], sample_pairs[:, 1]])

# 顯示圖片和結果
show_images_and_results(sample_pairs, predictions)

from google.colab import drive
drive.mount('/content/drive')